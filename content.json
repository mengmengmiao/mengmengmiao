[{"title":"MLY翻译 -- Machine Learning Yearning 目录","date":"2027-01-25T13:11:50.000Z","path":"2027/01/25/this-is-meng/","text":"NG新出了一本书：Machine Learning Yearning，里面有各种指导机器学习落实到项目的建议，来自NG的经验，希望对做实验有帮助。 1.为何需要机器学习策略？ 2.如何用这本书帮助你的团队？ 3.预备知识和符号约定 4.规模（scale）促使机器学习进步 5.开发集和测试集 6.开发集和测试集需要来自同一分布 7.开发集和测试集需要多大？ 8.为你的团队选择一个单数值评价度量吧 9.优化度量和满意度量 10.有了开发集和度量，能加速迭代 11.何时改变开发集和度量？ 12.关键点：建立开发集和测试集的建议 13.错误分析：通过观察开发集来评价ideas 14.错误分析：同时考虑多个ideas","tags":[{"name":"翻译","slug":"翻译","permalink":"https://mengmengmiao.github.io/tags/翻译/"}]},{"title":"如何远程ssh运行图形化应用？putty+Xming","date":"2017-03-08T14:00:54.000Z","path":"2017/03/08/如何远程ssh运行图形化应用？putty-Xming/","text":"参考http://www.bubuko.com/infodetail-807886.htmlstep 1 ：先去搜Putty.exe装在windows上。step 2 : 搜Xming装在windows上。（到sourceforge上下载：http://sourceforge.net/projects/xming/?source=typ_redirect， 分别下载 xming 与 xming-fonts。） Xming-6-9-0-31-setup.exe Xming-fonts-7-5-0-11-setup.exe 装完Xming和Xming-fonts，点XLaunch，一路next，直到结束。step 3 ：Unix/Linux 服务器的配置 修改下要登录的服务器的配置文件，增加对 X11 Forwarding的支持： sudo vi /etc/ssh/sshd_config: （在文件的末尾，增加以下配置） X11Forwarding yesstep 4 ：Putty配置 session - &gt; Host Name填服务器IP，port填22，connection type选ssh，save session随便填个名字 - &gt; 点SSH下的X11 - &gt; 选择enable X11 forwarding ，X display location填localhost:0,MIT-Magic-Cookie-1填上 - &gt; 选Session，点save","tags":[]},{"title":"PSCP windows传输文件/文件夹到linux","date":"2017-03-08T09:53:38.000Z","path":"2017/03/08/PSCP-windows传输文件-文件夹到linux/","text":"step 1 :下载Putty，连上linux。下载PSCP.exe。下载step 2 : windows打开cmd，cd到PSCP.exe所在目录传文件step 3 : dos窗口输入PSCP C:/Users/admin/Desktop/meng.txt meng@1.1.1.1：，这样就拷贝meng.txt到你的linux用户主目录了传文件夹step 3 ：用putty连接linux ，在主目录下创建一个文件夹meng；打开windows的cmd，转到PSCP.exe所在目录，执行PSCP -r D:/meng meng@1.1.1.1:。这样文件夹就拷贝到linux用户主目录的meng文件夹里了。","tags":[]},{"title":"海洋遥感论文总结","date":"2017-03-08T04:44:33.000Z","path":"2017/03/08/“海洋遥感论文总结/","text":"关键字：海洋遥感，光学遥感(optical remote sensing)，目标识别(object recognition),目标检测（object detection）海洋遥感相比与陆地遥感、气象遥感难度更大，在全球气候变化、大洋环流、赤潮检测等领域具有重要作用。 1.Ship Detection in Spaceborne Optical Image with SVD Networks 期刊：IEEE Transactions on Geoscience &amp; Remote Sensing，2016 目标：ship；spaceborne optical image；数据来源于委内瑞拉遥感卫星（VRSS-1）和GaoFen-1（GF-1）卫星的图像，作者自己收集的数据，这部分数据用于训练和测试，另外从google地图选了600张ship图（加上从那两个卫星提取的ship图片）用于svm的训练； 算法：SVD Network，两阶段：第一阶段提取ship candidate，第二阶段对candidate用svm分类。 ps：这个文章说没有公共船舶检测数据集，没有人公布其源代码或软件。 2.Ship Detection in Images Obtained from the Unmanned Aerial Vehicle (UAV) 期刊：Indian Journal of Science and Technology 目标：ship；无人机拍摄视频；数据来源于Google地图，Yandex地图，一小部分来自互联网（共1000张）； 算法：使用一个形状级联和自动提取特征级联（在此部分使用DNN） ps：是将训练好的网络应用于识别无人机视频中的ship 3.Compressed-Domain Ship Detection on Spaceborne Optical Image Using Deep Neural Network and Extreme Learning Machine 期刊：IEEE Transactions on Geoscience and Remote Sensing，2015 目标：ship；spaceborne optical image；数据来源 4000张 5m分辨率的SPOT 5全色图片，大小为2000*2000，这个数据集是作者建立的； 算法：JPEG2000压缩域提取的小波系数进行候选船的提取，深度神经网络用来进行高层特征的提取和分类，极限学习机用来更有效低池化特征和做决策。 4.Rotation Sliding Window of the Hog Feature in Remote Sensing Images for Ship Detection 会议：2015 8th International Symposium on Computational Intelligence and Design 目标：ship；数据来源 404正样本，来自google地图，410负样本，来自high random I satellite data； 算法：Rotation Sliding Window+HOG+SVM 总结：在google上搜索了几天，发现在海洋遥感这一块，满足海洋遥感+光学图像两个条件的，识别ship的最多，而识别coastline/shoreline（海岸线移动），island，iceberg，海面油膜（远红外），海浪（预测风暴），海冰（有时会用到雷达图像），悬浮泥沙，海面污染，赤潮，叶绿素，海色等的非常少 5.基于光学遥感的海岛识别及算法研究 期刊：博士学位论文（浙江大学），2010 目标：海岛；光学图像；数据来源TM、ETM+、SPOT遥感数据，我觉得也是自己选取的实验数据 算法：几何精纠正、像元灰度重采样、二值化提取海岛图斑、Rs、Gis和DEM和数据的一体化合成等改进算法 6.基于SIFT-SVM的北冰洋海冰识别研究 期刊：图像与多媒体技术，2017 目标：海冰；SAR图像（实在找不到光学的）；论文中只说是一张图片分成198个子图像，我觉得也是自己选取的实验数据 算法：SIFT+K-menas+SVM（分割） 7.基于图像处理的海冰识别与追踪方法 期刊：硕士学位论文（大连理工大学）2014 目标：海冰；光学图像，EOS和普通拍摄图片；数据来源，作者收集 算法：分割算法 8.高分辨率可见光遥感图像港口及港内目标识别方法 期刊：硕士学位论文（中国科学技术大学），2005 目标：海冰；光学图像；Google Earth，QuickBird 算法：模仿人类利用记忆知识辨别事物的原理，利用对港口目标的先验信息的适当表述，采用SIFT 特征匹配的方法，判断并识别图像中的港口目标。 9.遥感图像中港口目标识别技术 期刊：南京航空航天大学学报，2008 目标：港口；没说用的什么图像，看着像光学；25张图像，作者自己收集 算法：分割 10.遥感图像中港口目标的检测与识别 期刊：硕士学位论文（哈尔滨工业大学），2008 目标：港口；光学图像；作者自己收集 算法： ps：我觉得一旦用于港口这种复杂目标的识别图像，都是光学的，光学的含有的纹理更多。 11.大尺度遥感图像中港口目标快速识别 期刊：模式识别与人工智能 目标：港口；光学；作者自己收集，18块10000*10000的1m分辨率的图像 算法：海陆分割，图像分块；EM算法、阂值分割方法、快速提取目标候选区域方法 总结：在ship、海岛的识别上，和我现在做的识别流程很像，但海冰、港口的识别，多用分割算法以及其他一些算法，港口内目标的识别则在加上港口这一先验条件下，再去识别，感觉此时的识别和我现在做的识别有点像。而海岸线的提取，则用一些其他的方法，轮廓提取。做海浪识别的我没搜到，可能对海浪的强度进行研究更有意义。赤潮也是，单纯的识别赤潮应该是无意义的，识别出面积什么的更有意义吧。","tags":[]},{"title":"安装faster rcnn","date":"2017-03-07T12:31:48.000Z","path":"2017/03/07/安装faster-rcnn/","text":"代码：https://github.com/rbgirshick/fast-rcnn Installation (sufficient for the demo)0.可能需要Python安装包：cython，python-opencv，easydict 先装一个python包管理器pip： sudo apt-get install python-pip 再安装那三个包 sudo pip install cython sudo apt-get install python-opencv (进入python，import cv2可看到是否安装成功) sudo pip install easydict1.从git clone faster r-cnn git clone –recursive https://github.com/rbgirshick/fast-rcnn.git2.cd 到py-faster-rcnn/lib （rbg的第二步不用管，本文中，依然使用py-faster-rcnn而没用FRCN_ROOT） make3.Download pre-computed Faster R-CNN detectors（rbg的那个步骤4，在已经安装了caffe的情况下，不用再做） cd $FRCN_ROOT ./data/scripts/fetch_faster_rcnn_models.sh Demo #After successfully completing basic installation, you’ll be ready to run the demo. cd $FRCN_ROOT ./tools/demo.py 出现错误： import error no module named _caffe。（在caffe-master下的py-faster-rcnn下执行./tools/demo.py,而不是和caffe-master并列的那个） 解决方法： #回到caffe-master make distribute #make dir for custom python modules, install caffe mkdir ~/python mv distribute/python/caffe ~/python #set PYTHONPATH (this should go in your .bashrc or whatever #回到用户主目录， export PYTHONPATH = $PYTHONPATH:~/caffe-master/python/caffe source ~/.bashrc 出现错误： importERROR no module named skimage.io 解决方法： #直接使用终端安装： #回到用户主目录 pip install -U scikit-image (过程漫长) 出现错误： imortERROR：no module named google.protobuf.internal 解决方法： sudo apt-get install python-protobuf 出现错误： ImportERROR: no module named gpu_nms 解决方法： 在py-faster-rcnn的lib中make 出现错误： ImportERROR：no module named _tkinter,please install the python-tk package 解决方法： sudo apt-get install python-tk 出现错误： Check failed:ReadProtorFromTextFile(param_file,param) failed to parse NetParameter file: / home/meng/caffe-master/py-faster-rcn/models/pascal_voc/VGG16/faster_rcnn_alt_opt/faster_rcnn_test.pt ***Check failure stack trace*** 这个问题难解决，主要是因为py-faster-rcnn用的caffe是旧版本，而我的电脑上装的是新版本的，所以出现了这么多问题。所以做到这里，我决定把py-faster-rcnn的旧版本文件用新的替换下来（新文件来自caffe新版） 1.编译/py-faster-rcnn/caffe-fast-rcnn cd py-faster-rcnn/caffe-fast-rcnn cp Makefile.config.example Makefile.config 更改Makefile.config文件： #In your Makefile.config, make sure to have this line uncommented WITH_PYTHON_LAYER := 1 #Unrelatedly, it’s also recommended that you use CUDNN USE_CUDNN := 1 #配置一些引用文件（增加部分主要是解决新版本下，HDF5的路径问题） INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/lib/x86_64-linux-gnu/hdf5/serial/include LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu/hdf5/serial #启用Intel Parallel Studio XE 2016 BLAS := mkl #配置路径，实现caffe对Python接口的支持 PYTHON_LIB := /usr/local/lib #启用OpenCV 3.0, 去掉”#” OPENCV_VERSION =3 进行编译： make -j8 &amp;&amp; make pycaffe 因为这个版本所用的cudnn为旧版本的，可能与新环境的cudnn不兼容，导致出现如下错误： make: * [.build_release/src/caffe/util/db.o] Error 1 (可能是这个，类似吧，有点乱。) 解决办法： 1).将/py-faster-rcnn/caffe-fast-rcnn/include/caffe/util/cudnn.hpp 换成最新版的caffe里的cudnn的实现，即相应的cudnn.hpp. 2).将/py-faster-rcnn/caffe-fast-rcnn/src/caffe/layer里的，所有以cudnn开头的文件，例如cudnn_lrn_layer.cu，cudnn_pooling_layer.cpp，cudnn_sigmoid_layer.cu。 都替换成最新版的caffe里的相应的同名文件。 再次make -j8 &amp;&amp; make pycaffe 会遇到错误： make: * [.build_release/src/caffe/layers/cudnn_relu_layer.o] 错误 1 解决方法： 将/py-faster-rcnn/caffe-fast-rcnn/include/caffe/layers的，所有以cudnn开头的文件，例如cudnn_conv_layer.hpp，cudnn_lcn_laye.hpp 都替换成最新版的caffe里的相应的同名文件 遇到错误： ImportError:no module named yaml 解决方法： sudo apt-get install python-yaml 遇到错误： “/home/meng/.local/lib/python2.7/site-packages/matplot file “/usr/lib/python2.7/lib-tk/Tkinter.py” self.tk = _tkinter.create(screenName,baseName,className,interative,wantobjexts.useTk,sync,use) _tkinter.TclError: no display name and no $DISPALY environment variable 解决方法： 这错误是因为用putty远程登陆导致的，那个窗口弹不出来。给windows装个Xming吧。 2.运行faster-rcnn里的demo cd py-faster-rcnn/tools ./tools/demo.py","tags":[]},{"title":"understanding deep learning requires rethinking generalization","date":"2017-02-20T07:16:05.000Z","path":"2017/02/20/understanding-deep-learning-requires-rethinking-generalization/","text":"摘要：尽管深度神经网络很大，它们表现出的训练性能和测试性能之间只有非常小的差异。以前，人们把小的泛化误差归因于模型家族的属性（个人理解是这类模型的天生具有的优势）或者是训练时使用的正则化技术。通过广泛的系统实验，我们展示了这些传统方法为何不能解释大的神经网路在实际中泛化能力强。具体来说，我们的实验建立在最新的用随机梯度下降法训练的用于分类图片的卷积神经网络容易拟合标注随机标签的训练数据。这种现象在质量上不受显式正则化的影响，即使我们用完全非结构随机噪声来替换真实图像，也会发生这种现象。我们用理论结构证实了这些实验结果：一旦参数的数量超过数据点的数量，简单深度两个神经网络(simple depth two neural networks)已经有一个完美的有限样例表达式。我们通过对比传统模型来解释实验结果。//1.正则化是导致DNN有泛化能力的原因之一吗？//2.一旦参数超过数据点，网络就能记住所有的数据。所以网络只是单纯地记住了，还是学习了模式，还是两个都有？1 引言DNNs的可训练的模型参数通常都比样本量大，尽管如此一些模型仍能表现出较小的泛化误差（即训练误差training error和测试误差test error相近）。当然，也有一些模型表现的很差。那么，什么使神经网络有的表现差有的表现好呢？关于这个问题的回答不仅能帮助我们构建一个易理解、有理论支撑和可靠的神经网络模型。 当参数数量大时，需要某些形式的正则化来确保泛化误差小。正则化也可以隐含在某些情况中，如早早停止迭代。1.1 贡献在我们的工作中通过展示传统泛化观点不能区分具有完全不同泛化能力的神经网络，提出对传统的泛化观点的质疑。随机性测试。实验的第一组就是用随机标签数据集训练几个标准的框架。我们得到： DNN容易拟合随机标签。具体来说，当在完全随机标签的真数据上训练神经网络时,训练误差为0。当然，测试误差不会比随机猜更好，因为训练标签和测试标签没有关系。换句话说，不改模型架构、模型大小、模型超参和优化器，我们就能使模型泛化能力产生很大的改变。虽然上述实验结果看起来简单，但它从统计学习角度来说，却有深刻影响：1、神经网络的容量已经足够暴力记忆所有的额数据集了2、在随机标签数据集上训练也很容易。事实上，与用真实标签训练相比，用随机标签训练的训练时间只增加了一个小的常数因子。3、随机化标签只是一种数据变换，所以只变了数据，其他所有的学习问题都没变。 扩展第一组实验，用完全随机像素（例如高斯噪声）代替真图片，神经网络仍然拟合数据并且训练误差为0.这表明，神经网络能拟合随机噪声。改变随机化的程度，从无噪声到完全噪声，在从零到完全的中间会有一些标签是真的，在这些真标签中，仍存在一定的信号。随着噪声程度上升，泛化误差会稳定地变差，这表明神经网络能够捕捉到那些信号，同时用暴力记忆去拟合噪声。显式正则化的作用。 显式正则化，例如权重衰减（weight decay）、弃权（dropout）、数据增加（data argumentation），不足以解释泛化误差。换句话说， 显式正则化可能提高泛化误差，但是既不必要也不足以控制泛化误差。显示正则化能排除琐碎的解决方案。显示正则化似乎更多是调整参数，通常补助提高最终的测试误差，但是缺乏所有正则化并不一定意味着较差的泛化误差。有限样例表达式。我们实验观察到，一般大的神经网络就能表达标志随机标签的训练集。例如，我们展示了一个双层ReLU网络，它有p=2n+d个参数，它能表达随机标签的n个样例（d维）（这是怎么算的？）。 在样例多时，用两层神经网络肯定每层宽度都很大，若用k层神经网络，那每层只需要O(n/k)个参数。隐式正则化的作用。虽然显式正则化不是必须的，但肯定不是所有拟合训练数据的模型都有很好的泛化能力。事实上，stochastic gradient descent是隐式正则化。我们用线性模型看看SGD是怎么扮演隐式正则化角色的。对于线性模型，SGD总是熟练到具有最小范数的解。因此，算法本身隐含地使解决方案正则化。虽然这不能解释为什么一些模型泛化能力比另一些好，(这论文咋这样，又是三不知)，但是这个问题确实需要更多调查：这些使用SGD训练的模型都有什么共同属性？注释：1.训练误差判定一个给定的问题是不是容易学习的，测试误差反映了模型对未知的测试数据的预测能力（泛化能力），泛化误差反映了学习方法的泛化能力，泛化误差就是学习到的模型的期望风险。现实中通常采用测试误差评价泛化能力，但因测试数据集有限，所以评价结果并不可靠。","tags":[]},{"title":"Synthesizing the preferred inputs for neurons in neural networks via deep genetator networks","date":"2017-02-18T11:03:06.000Z","path":"2017/02/18/Synthesizing-the-preferred-inputs-for-neurons-in-neural-networks-via-deep-genetator-networks/","text":"摘要理解神经网络的内部是如何运行的一种方法是研究它的每个神经元学会检测了什么。这样的一种方法叫做激活最大化（AM），这种方法合成高度激活神经元的输入（例如，图像什么意思，合成输入到什么里的输入？）。在本文，我们通过利用一个强大的，学习过的先验：DGN，大大将AM的定性状态提高到目前最好。算法（1）生成定性的最先进的合成图像，图像看起来像真的（2）以可解释的方式揭示每个神经元学习的特征（3）对于新的数据集泛化能力好，并且对不同的网络架构在不用重新学习先验的情况下有一定的好的泛化能力（4）可以被认为是高质量的生成方法（在这种情况下，通过生成新颖，有创意，可识别的图像）。1 简介和相关工作","tags":[]},{"title":"MLY -- 14.Evaluating multiple ideas in parallel during error analysis","date":"2017-02-18T05:08:00.000Z","path":"2017/02/18/MLY-14-Evaluating-multiple-ideas-in-parallel-during-error-analysisi/","text":"你的团队有提高猫检测器的几个点子： 解决狗被分类为猫的问题 解决“大猫”（狮子，豹等）被认为是家猫（宠物）的问题 提高系统在模糊图像上的性能 …… 你可以并行地评估所有这些点子。我通常创建一个电子表格，并在查看这100张误分类开发集图片时填写这张表格，并记下有助于我记起具体是哪个例子的评论。下面用四个图片来演示我是怎么做的： image dog great cat blurry comments 1 &radic; 不平常的斗牛犬颜色 2 &radic; 3 &radic; &radic; 狮子;雨天在动物园拍摄的照片 4 &radic; 树后面的豹 % of total 25% 50% 50% 上面的图片3既是大猫又是模糊图片：一个例子可以属于多种类别。这就是为什么表格底部的百分数加起来不等于100%的原因。虽然在上述描述过程中，我首先确定类别（狗，大猫，模糊图片），然后将误分类图片分到每个类别中，在实际中，一旦你开始查看那些抽取的误分类图片，你可能会被启发从而提出新的类别。例如，你在查看了十几个图片后，意识到很多误分类图片是被Instagram过滤器预处理过后的图片。此时，你就可以在电子表格上加上Instagram一栏了。人工查看误分类图片，并在查看时问问自己如何/是否能够给出这些图片的正确标签，将能启发你提出新的错误类别和解决方案。最有用的错误类别是针对它你已有了提升方案的类别。例如，Instagram类别将是最有用的，如果你有了一个“撤销”Instagram过滤器从而将图片恢复到原始图片的方法。但你不必纠结于已经有了改进想法的错误类别；错误分析阶段的目标是建立你关于“哪个领域是最有前途的、最值得关注的”的直觉。错误分析是一个迭代过程。你可以从没有任何类别开始。通过查看图像，你可能会想出一些关于错误类别的ideas。然后，在对一些图片手工分类后，你可能会受到启发并提出新的类别，然后返回按照新类别重新检查图片，重复此循环。假设你完成了100个误分类开发集图片的错误分析，并得到： image dog great cat blurry comments 1 &radic; 不平常的斗牛犬颜色 2 &radic; 3 &radic; &amp;radic 狮子；雨天在动物园拍摄的图片 4 &radic; 树后面的豹 … … … … … % of total 8% 43% 61% 你现在知道了强调消除狗狗错误的项目最多只能消除8%的错误，致力于消除大猫和模糊图片的错误能够提高更多。你可以致力于后两个类别之一。如果你的团队有足够的人，可同时追求多个方向，你可以要求一些工程师致力于大猫和模糊图片两个类别。错误分析不会产生一个刚性(rigid)的数学公式，告诉你哪个任务应该是优先级最高的。你还必须考虑你希望在不同类别上取得多少进展，以及处理每个类别所需的工作量。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://mengmengmiao.github.io/tags/翻译/"}]},{"title":"MLY -- 13.Error analysis:look at dev set examples to evaluate ideas","date":"2017-02-17T12:48:15.000Z","path":"2017/02/17/MLY-13-Error-analysis-look-at-dev-set-examples-to-evaluate-ideas/","text":"当你在玩你的猫app时，你发现几个把狗狗分类成猫的例子。但是有些狗狗真的很像猫！你的团队成员提出结合第三方软件将会使系统在处理狗狗图片上更好。但这将会花费一个月，团队成员对此很是热情。你应该要求他们做吗？在投入一个月在这个项目上之前，我建议你首先评估一下这样做后系统的准确率会提高多少。然后你能更理性地决定这样做是否值得，或者你最好把时间用在其他任务上。具体来说，你可以这样做：1.从你的系统错误分类的开发集中抽取100个，换句话说，就是系统犯错的典型例子。2.人工查看这些图片，看看这些图片中狗狗图片占的比例。观察被误分类图片例子的过程称为“错误分析”。在本例中，如果你发现只有5%的误分类图片为狗狗图片，那么无论你在狗狗问题上做了多少提升，你都不会摆脱大于5%的错误（因为这5%确实是狗狗图片）。也就是说，5%是第三方软件能帮助你的系统的“天花板”。因此，如果你下载的系统的准确率是90%（10%的错误率），那么使用第三方软件后，最好结果就是90.5%的准确率（或者说9.5%的错误率，105%=0.5%）。作为对比，如果你发现50张错误分类图片都是狗狗图片，那么使用第三方软件可能会对你的系统产生较大的影响，可以使系统从90%的准确率提升到95%（1050%）。这种对错误的简单计数过程可以使你估计使用第三方软件能产生的价值，它提供了定量依据，以此决定是否作出这笔投资。错误分析能帮你弄清不同的方向具有的潜在价值。我曾见过很多工程师都不愿进行错误分析。投入并实现ideas是一件很令人兴奋的事，但质疑idea是否值得投入时间却不是那么令人兴奋。但你不去质疑，可能导致你的团队花费一个月的时间才意识到，这个idea只能产生一点点好处。人工检测100张图片并不会花费很多时间。即使一分钟看一张，两个小时你也能看完。用两个小时，就能节约一个月的无用功，多合算！“错误分析”是指检查算法误分类图片样本的过程，以此来理解错误的深层原因。这既可以使你为应进行的步骤进行优先级的排序（如本例中，是组合第三方软件还是选择其他idea），又能激发新的方向（下一章我们会谈到）。接下来的几章还将介绍进行误差分析的最佳实践。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://mengmengmiao.github.io/tags/翻译/"}]},{"title":"MLY -- 12.Takeways:Setting up development and test sets","date":"2017-02-17T09:07:57.000Z","path":"2017/02/17/MLY-12-Takeways-Setting-up-development-and-test-sets/","text":"选择能反映“你未来期望得到并且希望算法在其上能表现得好的数据”的分布的开发集和测试集。这可能和你训练集的分布不同。 尽量使开发集和测试集的分布相同 为你的团队选择优化单数值评价度量。如果有多个目标，可以考虑将他们组合成单个公式（例如对多个错误度量（error metrics）取平均），或者定义满意度量和优化度量。 机器学习是个高迭代过程：在发现能使你满意的点子之前，你可能需要尝试很多点子。 拥有开发/测试集和单数值评价度量能帮助你评估算法，从而使迭代更快。 当开始一个全新的应用时，尽量尽快建立开发/测试集和评价度量，尽量少于一周。在成熟的应用上，可以花费时间长点儿。 以前启发式的训练/测试集按70%/30%分割的策略在数据量很大时就不适用了。开发和测试集可以少于30%。 你的开发集应该大到可以检测出算法准确率的有意义的改变，但没有必要太大。你的测试集应该大到对最终的算法的表现有个可信服的评估。 如果你的开发集和度量不再能指引正确的方向，你应快速改变它们：（i）如果过拟合了开发集，应获得更多的开发集数据。（ii）如果实际分布和开发/测试集的分布不同，获得新的开发/测试集。(iii)如果度量不再能测量对你来说重要的东西，改变度量。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://mengmengmiao.github.io/tags/翻译/"}]},{"title":"Understanding Neural Networks Through Deep Visualization","date":"2017-02-17T05:19:26.000Z","path":"2017/02/17/Understanding-Neural-Networks-Through-Deep-Visualization/","text":"摘要近年来，人们在训练大型深层神经网络（DNNs）方面取得了巨大的进步，包括在训练卷积神经网络识别自然图片上也取得了显著成功。然而，我们对这些网络如何工作的理解，特别是中间层执行的计算的理解，已经落后。通过开发用于可视化和解释的神经网络的更好的工具，会促进该领域的进步。我们做了两个这样的工具。第一个工具是可视化被训练好的convnet在处理一个图片或视屏时的每层的激活值。我们发现，当用户输入时，实时激活值的变化，查看这样的变化有助于我们建立convnet是如何工作的直觉。第二个工具通过图像空间中的正则优化使得可视化DNN每层的特征。因为这个想法的先前版本产生不太可识别的图像，在这里我们介绍几种新的正则化方法，将这几种正则化方法结合起来会产生质量（qualitatively）更清晰，更可解释的可视化。引言神经网络长期以来被称为“黑盒子”，由于大量相互作用的非线性部分，难以准确理解任何特定的、被训练的神经网络功能。（模式+暴力记忆）大型神经网络更难研究，例如要理解AlexNet DNN涉及到要为60million的参数赋予意义。理解网络学了什么很有趣，但它也是进一步改进模型的一个关键方法：通过理解当前一代模型提供的直觉应该提出使它们更好的方法。例如，解卷积技术（可视化DNN的隐含层学到的特征）暗示了较小的卷积滤波器的架构变化，导致了2013 ImageNet最先进的性能。新手可用这两个工具理解自己的模型为什么能work（或不work）。专家可用我们的工具从DNN内部如何工作的直观感受中受益。第一个工具交互地绘出DNN每层的激活值们。如输入的是静态图片，工具会提供缓慢、详细的调查；若输入的是视屏，工具会突出显示DNN对动态输入的响应。目前，从用户计算机的摄像机来的视屏时实时处理的，用户可通过移动、遮挡、组合物体，来看看不同的特征在网络中是如何响应的。第二个工具可视化DNN每层的每个神经元计算出的特征。看看什么样的特征被学习了，对了解DNN如何工作和激起如何改善网络的直觉很重要。试图理解DNN的每个层执行什么计算是越来越受欢迎的研究方向。一种方法是研究将每个层作为一组，并调查每层中的神经元们执行的计算类型。这种方法是信息性的，因为每一层中的神经元彼此交互，将信息传递到更高层，因此每个神经元对整个函数的贡献取决于该神经元在该层的上下文。另一种方法是，尝试解释每个神经元计算的函数。过去的研究大体可分为两派：以数据为中心和以网络为中心。前者需要被训练的DNN和数据；后者仅需要被训练的网络。一种以数据为中心的方法是显示来自训练或者测试集的图片，这些图片能对独立单元（个人认为是，神经元）产生高或低的激活。另一个是解卷积方法，强调特定图像的部分，这部分能激活神经单元（neural unit）。以网络为中心的方法直接研究网络，没有来自数据集的任何数据。例如，Erhan等合成的图片，能使特定单元产生高激活。从初始输入x=x0开始，计算由该输入在某个单元i处引起的激活ai(x)，然后沿着梯度∂ai（x）/∂x在输入空间中采取步骤，以合成导致更高的单元i的激活值的输入（x？），最终终止于x*（以上所述是个迭代过程，看出来了吗），这个x*被认为是所述单元的优选输入。在这种情况下，输入空间是一个图片，x*可以直接显示出来。其他人也使用这种方法，使用梯度找到导致更高或更低的激活的图片。这些基于梯度的方法很简单，但是优化过程倾向于产生不像自然图片的图片。它们由一系列“黑客”组成，这些“黑客”导致高（或低）的激活值：极端像素值，结构化高频模式和没有全局结构的基本图案。最近的研究能使我们更好理解为何这些黑客能实现激活。具体来说，这些黑客能用于被正确分类的图像，使得这些图像在经过一些不可察觉的小变化后被错误分类，这些黑客在没有梯度信息的情况下能产生“愚弄例子”，导致极端激活的非自然图像的丰度可以用神经网络的局部线性行为来解释。能使用上述优化过程产生有用的可视化吗？事实证明可以，如果能适当正则化优化过程。我们基于前人的工作，贡献三种不同的正则化形式，当组合这些正则化时，会比先前产生更可识别的，基于优化的样本。因为优化是随机的，通过从不同的初始图像开始，我们可以产生一组优化的图像，其方差提供关于单元学习的不变性的信息。本文做出两大贡献：1.2.我们延续过去在输入空间内可视化首选（preferred）激活模式的努力，通过添加几种新类型的正则化，这种方式为大型ConvNets产生了目前为止最可解释的图像。3 Visualizing via Regularized Optimization本工作的第二个贡献是引入了几个正则化方法，以将优化得到的图片偏向视觉上更加可解释。虽然这些正则化方法单独就很有帮助，它们组合起来甚至更有效。我们发现了一种有用的组合方式：通过超参数搜索，下面将会讨论这中方式。我们的网络在ImageNet上训练，在把训练图片放入网络中训练之前，先减去ImageNet中的图片的每个像素的平均值。因此，网络的输入x可以看做零中心输入。我们可将优化问题看作找到图像x*: 4 discussion and conclusion我们提出了两个用于辅助解释被训练的神经网络的可视化工具。从这两个工具中得到的直觉可促使我们(什么时候我们不再依靠直觉，而是依靠理论帮助我们改进网络呀)提出几个改进方法和未来研究的方向。这里，我们讨论几个这样的想法。工具一揭示了后几个卷积层的表示（representations）倾向于在某种程度上是局部的，其中通道（channels）对应于特定的自然部分（例如轮，脸），而不是完全分布式编码的尺寸（instead of being dimensions in a completely distributed code）。也就是说，不是所有的特征对应自然的部分，这会提高神经网络对这个世界不同的分解的可能性。这些可视化表明，进一步研究所学到的表示的确切性质——是否他们在单个通道中是局部的还是分布在几个通道中——可能是有趣的。表示的局部性还表明，在迁移学习期间，当在conv4或conv5表示的顶部训练新模型时，使用稀疏连通可能是有帮助的，因为可能有必要组合来自这些层的少数特征以在较高层创建重要特征。第二个工具——新的正则化，能够改进、可解释、优化学习到的特征的可视化——将会帮助研究者和从业者理解、调试、提高他们的模型。可视化还揭示了一个正在进行的故事的新的扭曲（twist）。以前的研究表明，有判别力的网络可以容易地被”在图片空间添加某些结构的噪声“愚弄或者被黑（hacked）。导致网络这样的原因是，有判别力的训练会导致网络不去理没有判别力的信息，例如学习检测美洲虎是通过匹配它们皮毛上特殊的斑点，而忽略了它们都有四条腿的事实。(应该是训练集中是老虎，羊，狗这种四条腿的动物)由于这个原因，它被视为一种无尽的努力：创建一个生成模型，其中从所有可能图像的空间上的宽分布中随机地采样x，然后通过将x移动到“一个满足一些类标签y的先验p(x)和后验p（y|x）”的区域来迭代地将x变换为可识别的图像。过去的尝试通过使用这种方法产生不现实的图像很大程度上支持了这种观点。然而，这里给出的结果提示了另一种可能性：先前使用的先验可能太弱了（参见S1部分关于一个假设为什么需要强先验p(x)模型）。通过仔细设计或学习偏向现实的p(x)模型，可以利用存在于有判别力的P（y|x）模型中的大量参数，通过在两个模型下的强制概率来生成逼真的图像。即使使用简单的手工编码的p(x)模型作为正则化器，已经出现了在远距离像素之间的复杂依赖性（参加图4中占100个像素的甲虫）。这意味着有判别力的参数还包含来自训练集的重要的“生成”结构；也就是说，参数编码的不仅是美洲虎的斑点，而且在某种程度上也是它的四条腿。利用在更高层的输入和激活上学习的概率模型，更多的结构可能会显现出来。Dai等人的工作显示了是关于这方面的。虽然本文中的图像不像真的，但它们建议将区别训练的参数传递到生成模型——与通常的无监督预训练方法相反——这方向可能值得进一步研究。","tags":[]},{"title":"MLY -- 11.When to change dev/test sets and metrics","date":"2017-02-17T04:29:01.000Z","path":"2017/02/17/MLY-11-When-to-change-dev-test-sets-and-metrics/","text":"当开始做一个新项目时，我会快速选择开发集和测试集，因为这会给团队一个明确的目标。通常，我会要求我的团队在一周之内提出初始的开发集、测试集和度量，大多时候都不会多于一周。先提出一些不完美的东西使项目能前进下去，比过多考虑开发集、测试集、度量好的多。但是，一周时间线并不适用于成熟的应用。例如，垃圾邮件是一个成熟的深度学习应用。我曾见到在已经很成熟的系统上工作的团队花费数月的时间去获得好点儿的开发/测试集。如果在后续开发中，你发现初始开发集、测试集、度量偏离了目标方向（missed the mark），一定要快速地改进。例如，如果你的开发集+度量使分类器A得分优于分类器B，但是你的团队认为分类器B实际上对你的产品更好，那么这就可能是你需要改进你的开发集、测试集或者度量的时候了。1.实际的分布和开发集、测试集的分布不同假设你初始的开发/测试集主要由成年猫的图片组成。当发布了app后，出乎意料，你发现用户会上传很多幼年猫的图片。此时，开发/测试集的分布就不能代表实际的分布了。在这种情况下，你需要更新开发/测试集，使其更具代表性。2.过拟合开发集了重复地用开发集来评价ideas可能导致过拟合开发集。当项目开发结束时，需要在测试集上评估你的系统。如果你发现开发集的表现比测试集好，那么这可能就是过拟合开发集了。在这种情况下，你需要一个新的开发集（a fresh dev set）。如果你需要跟踪团队的进展，你可以用测试集定期评估你的系统（例如每周一次或每月一次）。但是不要用测试集做任何关于算法的决策，包括是否要回滚到上一个系统。如果你这么做了，系统将会开始过拟合测试集。并且不能再依赖测试集给出系统性能的完全无偏评估（当你发表论文或使用这个评估去做商业决策时就需要完全无偏评估）。3.度量（the metric）中不包括项目需要优化的东西假设对于猫分类器，你选择了分类准确度（classification accuracy）作为度量（metric），在这种度量下，分类器A比分类器B好。但是，当你实际去用这两种算法时，你发现分类器A偶尔会允许色情图片溜过去。即使分类器A准确率更高，但偶尔的一张色情图片会给用户留下坏印象，因此分类器A并不可取。此时，度量未能分辨出算法B实际上比算法A好。因此，度量不再可信，是时候改变度量了。例如，你可以改变度量使其惩罚色情图片通过。我强烈建议选择一个新的度量，并用这个新度量为团队定义一个新目标，而不是在没有可信度量的情况下工作太长时间甚至恢复到手动选择分类器。在项目期改变开发/测试集或评价度量是很常见的。初始的开发/测试集能帮助你快速进入迭代期。如果你发现开发/测试集或者度量不再能指引正确的方向，那也没事儿。只要改变它们并且保证你的团队知道新的方向就行了。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://mengmengmiao.github.io/tags/翻译/"}]},{"title":"MLY -- 10.Having a dev set and metric speeds up iterations","date":"2017-02-16T09:23:42.000Z","path":"2017/02/16/MLY-10-Having-a-dev-set-and-metric-speeds-up-iterations/","text":"很难事先知道什么算法最适合一个新问题。就算是经验丰富的机器学习研究人员通常也需要尝试一系列方法后才能发现一些令人满意的方法。当构建一个机器学习系统时，我经常：1.以一些如何构建系统的想法开始2.用代码实现这些想法3.做实验，实验会告诉我们哪些想法效果好。（通常，我开始的几个想法效果并不好）基于这些已学到的想法，我们回到第1步再产生更多想法，并循环下去。上图就是迭代过程。这一圈你走的越快，你的进展就越快。这就是为什么开发集和测试集重要：当你尝试一个想法时，你可以在开发集上测量想法的表现，这能使你快速地发现是否你正在朝着正确的方向前进。与此相对的是，假设你没有具体的开发集和度量（metric），每次你的团队开发一个新的猫分类器，就需要将这个分类器合并到你的app中，然后玩上几小时感觉一下新分类器是否有提升。这过程相当慢呀是不是？而且，当你的分类器从95.0%提升到95.1%时，你并不能通过玩app感觉出来这0.1%呀。拥有开发集和度量可以使你快速递检测出哪个想法会使分类集得到一点提升，从而使你快速判断出哪个想法需要再微调，哪个想法需要抛弃。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://mengmengmiao.github.io/tags/翻译/"}]},{"title":"Deep Nerual Networks are Easily Fooled:High Confidence Predictions for Unrecognize Images","date":"2017-02-16T08:48:18.000Z","path":"2017/02/16/Deep-Nerual-Networks-are-Easily-Fooled-High-Confidence-Predictions-for-Unrecognize-Images/","text":"摘要鉴于现在深度神经网络分类目标的水平已经接近人类了，自然人们会问计算机和人类的视觉之间存在什么差异？最近的一项研究显示，以人类不能察觉到的方式改变图像（例如狮子）可能导致DNN将图像标记为风马牛不相及的东西（例如，将狮子标记为图书馆）。在这里，我们展示了一个相关的结果：很容易产生完全不能被人类所识别的图像，但是最先进的DNN认为是具有99.99%置信度的可识别对象（例如，把白噪声标记为狮子）的图片。具体来说，我们采用在ImageNet 和MNIST上训练兵表现良好的卷积神经网络，然后使用此网络结合进化算法或者梯度上升找到被DNN标记为高置信度的图片。找到的图片可能人类完全不能识别，然而DNNs相信，几乎确定是熟悉的对象，我们称之为“愚弄图像”（愚弄例子）。我们的实验结果阐明了人类视觉和当前DNN之间有趣的差异，并提出关于DNN计算机视觉的通用性的问题。1 Introduction既然DNN对是视觉对象分类的能力和人媲美（sometimes），那么问题来了，计算机和人类视觉之间存在什么样的差异？最近有个研究揭示了DNN和人类视觉之间的主要区别。以人类不可察觉的方式改变最初正确分类的图片（例如狮子），DNN将会把它标记为风马牛不相及的东西（例如图书馆）。在本工作中，我们展示另一种区别：很容易产生完全不能被人类识别的图片（图1），但是DNN认为是置信度99%的可识别物体（例如把电视静息图像识别成摩托车）。我们发现，对于MNIST DNNs，即使将愚弄图片放入训练集再训练DNN，也不容易防止DNN被欺骗。虽然重新训练的DNN学习将负样例分类为愚弄图片，但重新训练后的网络还是可以产生一批愚弄此网络的图片。我们的发现还街漏了一个问题：与训练和测试过DNN的图片相比，在不同类别的图片上，DNN通常表现如何。图1.人类无法识别的演变(evolved)图像，但是在ImageNet上训练的最先进的DNN以置信度≥99.6％确定是一个熟悉的目标。 这个结果突出了DNN和人类之间识别对象的差异。图像是直接（顶部）或间接（底部）编码得到。 2 方法2.1 DNN模型选用AlexNet，使用ILSVRC的1.3-million-image训练。实际山个，我们用了caffe软件包训练好的AlexNet。选用AlexNet是因为它广为人知、公开和被训练过。在本文中，我们称AlexNet为ImageNet DNN。为了测试我们的结果适用于其他模型，我们还用来自xaffe的在MNIST上训练的LeNet（我们称MNIST DNN）进行了实验。2.2 用进化生成图像我们测试DNN的新图像是由进化算法生成的。进化算法中，哪些个体被选择取决于适应度函数，在我们的试验中DNN预测为某一类别的预测值最高的图像将被选择。一般，EA是单目标优化的（演变图像匹配一个ImageNet类）。而我们改为使用称为表型精英MAP精英的多维档案的新算法，能使我们同时演变一个群，这个群里的个体都是在那个类别下被DNN分类预测值最高的","tags":[]},{"title":"MLY -- 9.Optimizing and satisficing metrics","date":"2017-02-16T07:22:04.000Z","path":"2017/02/16/MLY-9-Optimizing-and-satisficing-metrics/","text":"其实，还有一种组合多个评价度量的方法。假设，你将准确率和运行时间看做同等重要的评价项，你需要从以下三个分类器中选择一个： classifier accuracy running time A 90% 80ms B 92% 95ms C 95% 1500ms 如按照上一章的方法，通过将准确率和运行时间放入一个公式中得到单数值度量看起来是不自然的： Accuracy -0.5*RunningTime你可以这样做：首先，确定能接受的运行时间，例如运行时间在100ms内都是可接受的；然后，在满足运行时间这个条件下，最大化准确率。这里运行时间是一个“满意度量”——分类器只需要在“满意度量”下足够好，这意味着，你最多能花费100ms。准确率是“优化度量”。如果你想平衡（trade off）N个评价项，例如模型的二进制文件大小（这对手机app很重要，用户们不会喜欢下载文件大的app）、运行时间、准确率，你可能考虑设置N-1项评价为“满意度量”。换句话说，你只需要这N-1个评价度量们满足一个确定值。在这种情况下，你就可以定义最后一个评价为“优化度量”。例如，为二进制文件大小和运行时间设置一个阈值，然后在这些些约束条件下优化准确率。最后，再举一例。假设你正在构建一个硬件设备：当用户通过麦克风说一个“唤醒词”时，系统被唤醒。例如，Amazon Echo被“Alexa”唤醒，Apple Siri被“Hey Siri”唤醒；Android被“Okay Google”唤醒，Baidu apps被“Hello Baidu”唤醒。你关心的评价项有假正率（false positive rate）——没有人唤系统时系统却唤醒的频率，假负率（false negative rate ）—— 当有人唤系统时系统没被唤醒的频率。开发这个系统时应设置的合理目标是：在每24小时不超过一次假唤醒（false positive）的条件下（满意度量），最小化假负率（优化度量）。一旦你的团队明确了要优化的评价度量，他们将会进展更快。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://mengmengmiao.github.io/tags/翻译/"}]},{"title":"MLY -- 8.Establish a single-number evaluation metric for your team to optimize","date":"2017-02-16T05:08:08.000Z","path":"2017/02/16/MLY-8-Establish-a-single-number-evaluation-metric-for-your-team-to-optimize/","text":"分类准确率(classification accuracy)是一个单数值的评价度量：将开发集（或测试集）输入分类器分类，分类器返回“被分类器正确分类的数据占输入数据集的比例”。如果分类器A获得97%的准确率，分类器B获得90%的准确率费，根据评价度量，分类器A较好。与此不同的是，精度率和召回率（precision and recall）就不是一个单数值评价度量：它用两个数值去评价分类器。多数值评价度量使得比较分类算法时变得困难。假设你的分类算法表现如下： classifier precision recall A 95% 90% B 98% 85% 这里，并不能直接看出两个分类器中哪个更好。 在实际开发过程中，你的团队将用不同的算法框架、模型参数、特征选择等。而使用单数值评价度量（如准确率）能快速地对这些算法的优劣做一个排序，从而看出哪一个算法更好。 如果你真的关心精确率和召回率，我建议你使用一种标准的方法将两种评价数值糅合成一个。例如，可取精确率和召回率的平均值作为评价数值；还可以取“F1 score”，F1 score是计算平均值的一种改进的方法，比取平均值的表现好多了。 classifier precision recall F1 score A 95% 90% 92.4% B 98% 85% 91.0% 单数值评价度量能让你从众多算法中快速选出哪个算法最优，它对众多算法进行偏好排序，因而明确了进展的方向。 最后，假设你分别在四个主要市场（(i)US,(ii)China,(iii)India,(iv)其他）跟踪你的猫分类器准确率，因此你得到四个度量。对这四个度量取平均或加权平均值，你就会得到一个评价数值。取平均或加权平均是将多个度量变成一个的最常用的方法。 ##注释： 精确率和召回率：以猫图片分类器为例，精确率是指在分类器分类成猫的图片中，真的是猫图片的比例。召回率是指在开发集（或测试集）中的猫图片被分类器分类成猫图片的概率。在高准确率和高召回率间，经常需要权衡（tradeoff）。 F1 score： 如果你想了解更多，可以点击 https://en.wikipedia.org/wiki/F1_score。F1 score就是精确率和召回率的几何平均值，是这样计算的 2/((1/precision)+(1/recall))。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://mengmengmiao.github.io/tags/翻译/"}]},{"title":"PathNet: Evolution Channels Gradient Descent in Super Nerual Networks","date":"2017-02-07T03:09:14.000Z","path":"2017/02/07/PathNet-Evolution-Channels-Gradient-Descent-in-Super/","text":"来自Google DeepMind，Google Brain,1月30的一片文章。 摘要：对AGI（artificial general intelligence，通用人工智能）来说，这将会是有效率的：多个用户同时训练巨大的神经网路、允许参数复用、不允许灾难性的遗忘。PathNet是这个方向的先行者。PathNet是一个使用agents嵌入神经网络中，agents的作用是发现网络中哪一部分可以用于新任务的神经网络算法。agents是贯穿整个网络的通路，它决定参数的哪个子集可以被使用和被反向传播算法更新。在学习期间。“竞争选择遗传算法”被用于选择用于复制和突变的神经网路的通路。通路适应度值是用费用函数（cost function）计算的通路的表现（performance）。我们成功论证了迁移学习（transfer learning）；将在任务A上学习的路径的参数固定并且为任务B重新演化一个新路径群，会比从头或在微调后更快地学习任务B。在任务B上演化的路径，部分重用在任务A上演化出的最佳路径。正迁移被证明为binary MNIST、CIFAR、SVHN监督学习分类任务和一组Atari and Labyrinth强化学习任务。这说明PathNet对于神经网络的训练具有一般适用性。最后，PathNet显著提高了并行异步强化学习算法的超参数选择的鲁棒性。 综述通用人工智能的一个合理需求是许多用户被要求在大量任务上训练相同的巨型神经网络。这是网络获得经验的最有效的方式，因为这种网络可以复用现有知识，而不是为每个任务都从头开始学习。为了实现这一点，我们建议给巨型网络的每个用户一群代理，这群代理的工作是尽可能有效的学习用户定义的任务。代理将通过在神经网络内执行动作来学习如何更好地复用神经网络环境中现有的参数。代理必须与正在为其他用户学习其他任务的其他代理并行工作，如果可能传输则共享参数，如果干扰显著则学习更新不相交的参数。每个代理本身可以由任意复杂的强化学习算法控制，但是在这里我们选择最简单的可能的“代理”，一个进化的单位。上述AGI的框架包括迁移学习，连续学习(continual learning)和多任务学习(multitask learning)。我们论文的motivation和最近的一篇论文“非常大的神经网络”相同，其中作者写到“神经网络吸收信息的能力受其参数数量的限制”。如果标准神经网络训练成本和模型宽度成二次方，而PathNet理论上具有相对于模型宽度的恒定计算速度，因为在任何情况下只有较大网络固定大小的子集用于向前和向后传播。我们的工作还涉及“卷积神经结构”，其中结构之间的模块的连接强度被学习，但是结构在整个时间不变（PathNet则不同）。本文介绍了PathNet，一种新颖的学习算法，支持迁移、连续多任务学习。图一说明了算法的运行过程。","tags":[{"name":"new papers","slug":"new-papers","permalink":"https://mengmengmiao.github.io/tags/new-papers/"}]},{"title":"MLY -- 7.How large do the dev/test sets need to be?","date":"2017-01-30T13:12:33.000Z","path":"2017/01/30/MLY-7-How-large-do-the-dev-test-sets-need-to-be/","text":"开发集应该足够大，大到可以检测出多个算法之间的不同。例如，分类器A的分类精度是90.0%，分类器B的精度为90.1%，开发集有100个样例，则开发集不能检测出这0.1%的不同（将开发集输入分类器A、B进行分类，A、B的结果都是90个样例的类标签正确，所以不能区分A、B）。就我所见过的机器学习问题来说，100个样例的开发集确实小了点儿。一般，开发集都是1000到10000这么大。当你有了10000个样例时，你就能检测出那0.1的提高啦(注释1)（我觉得0.01也能检测出来）。对于成熟而重要的应用，例如广告，网页搜索，产品推荐，我见过一些团队为哪怕提高0.01%的精确度而努力工作，因为这对公司的利益有直接的影响。在这种情况下，开发集可以远大于10000，以便检测出更小的提高。测试集的大小呢？测试集应该大到在测试你的系统的整体性能时，是可信服的。一个比较流行的方法是取30%的数据作为测试集，这种方法在适量数据(100到10000个样例)时，效果很好。但在大数据时期，有的机器学习问题的样例甚至超过了十亿，此时，开发/训练集占总数据的比例减少了，但数量变多了。其实没有必要具有过大的开发/测试集，只需要能评估你的算法就行了。 [注释1]： 理论上，还可以测试算法的变化是否引起统计显著性差异。实际中，多数团队都不做这个测试（除非他们要发表学术性研究论文），我发现统计显著性检验对临时进展（interim progress，即每次改变算法获得的改进）没有什么用","tags":[{"name":"翻译","slug":"翻译","permalink":"https://mengmengmiao.github.io/tags/翻译/"}]},{"title":"MLY -- 6.Your dev and test sets should come from the same distribution","date":"2017-01-28T05:26:41.000Z","path":"2017/01/28/MLY-6-Your-dev-and-test-sets-should-come-from-the-same-distribution/","text":"根据你app应用的市场：（i）US，（ii）China，（iii）India，（iv）Other，你将猫图片数据分为四个部分。若想要一个开发集和一个测试集时，我们可以随机地选两个作为开发集，剩下的两个作为测试集。例如，可以选US和India作为开发集，China和Other作为测试集。一旦确定好了开发集和测试集，你的小团队将专注于提高学习算法在开发集上的表现。因此，开发集应该反映你想要改进的任务：在四个地理位置上表现都好，而不是两个。此外，当开发集和测试集分布不同时，还会有问题：有可能你的团队将要构建一个在开发集上表现很好的东西，却发现这个东西在测试集上表现的很差。这种结果有多挫败和浪费精力，避免让它发生在你身上吧。举个例子：假设你的团队做出的系统在开发集上表现很好，而在测试集上却表现不佳。如果你的开发集和测试集来自于用一个分布，那么你会知道是过拟合开发集(是否还有可能是训练集过拟合？)了，此时明显的解决办法就是获得更多开发集数据。但是，若开发集和测试集来自不同的分布，那么就不容易找到解决方向了。有几个导致在测试集上表现不佳的原因： 过拟合开发集 测试集比开发集更严格。此时你的算法可能跟预期的一样好了，没有能改进很多的方法了 测试集不一定更严格，只是和开发集不同而已。所以在开发集上表现好的算法不一定在测试集上表现的也好。对于这种情况，你为提高算法在开发集上的表现所做的工作，就没用了。 在“机器学习应用”上工作已经够难了，开发集和测试集不匹配又将会带来不确定性：若算法在开发集上表现提高，是否在测试集上表现也会提高？开发集和测试集的不匹配让我们更难找出什么样的解决方向能奏效，从而使得很难确定工作的优先级。如果你正在处理 3rd party benchmark 问题，这个问题的创建者可能已经指定开发集和测试集来自不同的分布。在这种情况下，运气，而非技术，将会对算法表现有较大影响。如何将“在一个分布上训练的算法能泛化到其他分布上”是一个重要的科研问题。但是，如果你的目标是在一个特定的机器学习应用领域取得进步，而不是使科研问题进步，那么我建议你选择开发集和测试集来自同一分布，这会使你的团队更有效率。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://mengmengmiao.github.io/tags/翻译/"}]},{"title":"MLY -- 5.your development and test sets","date":"2017-01-28T02:52:40.000Z","path":"2017/01/28/MLY-5-your-development-and-test-sets/","text":"让我们回想一下猫图片那个例子：你们公司运行一个手机app，用户往app上上传许多不同物体的图片，而你想从这些图片中让机器自动找到猫图片。你的团队从不同的网站上获得了包含猫的图片（正样例）和不包含猫的图片（负样例）。然后将70%的图片用作训练集，30%的图片用作测试集。使用这些图片，你的团队构建了一个猫检测器，这个检测器在训练集和测试集上表现很好。但是，当你将这个分类器发布到移动端app时，其表现却很差。为什么会这样？你发现用户上传的图片与组成训练集的图片有不同的外观：用户上传的图片是用手机拍摄的，因此图片分辨率较低，模糊，并且光线不太理想。因你的训练/测试集都是由网站上的图片组成的，所以由训练集训练除的算法不能很好地泛化到手机图片的分布。在大数据时代之前，在机器学习中，随机70%/30%分割数据集为训练集和测试集是一个常见规则。这种规则可行，但是，在越来越多的“训练时的分布（例如上例网站图片）和最终关心的问题的分布（上例的手机图片）是不同的”应用上， 这种规则却不是一个好主意。我们通常定义： 训练集 – 用来训练你的学习算法 开发集(development set) – 用来调整参数，选择特征，根据学习算法做出其他决定。有时也叫hold-out交叉验证集。 测试集 – 用来评价学习算法的表现，不能将其用于对学习算法和算法参数的选择。 一旦你们定义里开发集和测试集，你的团队就可以尝试不同的ideas（例如，不同的学习算法参数），从而发现哪种ideas表现最好。开发集和测试集能使你的团队快速地看到你们的学习算法表现的怎么样。换句话来说，开发集和测试集能指引你的团队对机器学习系统做出最重要的改变。所以，你应该做到： 选择的开发集和测试集能够反映你期望将来能得到的并且算法在上面表现不错的数据的特点。换句话说，你的测试集不应该只是可利用的数据的30%，特别是将来的数据（移动端app图像）和你的训练数据（网站图像）不同时。如果你还没有发布app，没有用户的你可能不能得到能够精确反映算法将来处理的数据的数据集。但是，你可以尝试得到一些近似数据。例如，拉上你的亲朋好友，让他们用手机拍照片并传给你。一旦你的app发布了，你就能够根据用户的数据更新你的开发/测试数据集啦！假如，你没有任何途径能够得到一些近似数据，你也可以使用网站图像先开始。但你应该意识到，这会导致系统的泛化能力不好。我们需要判断一下，在构建很棒的开发集和测试集上应该投资多少。但是不要妄想训练时的分布和测试的分布相同。尝试挑选能够反映“算法最终能在其上表现好的数据”的样例，而不是你碰巧得到的什么数据（这里的for training应该理解成整个训练过程，包括训练，交叉验证和测试）。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://mengmengmiao.github.io/tags/翻译/"}]},{"title":"MLY翻译 -- 4.Scale drivers machine learning progress","date":"2017-01-27T02:39:40.000Z","path":"2017/01/27/MLY-Scale-drivers-machine-learning-progress/","text":"深度学习（神经网络）的很多想法已经存在几十年了，为什么这些想法现在才流行起来？促使机器学习进来的进步的两大因素是： 可得到的数据。现在，人们会花费更多的时间在数字设备上（例如笔记本，手机）。人们的数字行为产生了大量的数据，而这些数据可以用来训练我们的学习算法。 计算的规模。 也就是在近几年，我们才有计算能力训练足够大的神经网络，这种足够大的网络能利用我们拥有的巨大的数据集。 具体来说，即使你积累了更多数据，把这些数据用于训练旧的学习算法（例如逻辑回归），这些算法仍然表现平平。即旧的学习算法的学习曲线是“平坦”的，即使你给它更多数据，它仍然停止增长。这种情况就像旧算法不知道如何处理我们现在拥有的数据似的。对于同样的监督学习任务，如果我们训练一个小的神经网络，将会得到一个稍微好点的结果：这里，小的神经网络是指神经网络的隐藏单元/层/参数较小。如果你训练越来越大的神经网络，你将会得到越来越好的结果[注释1]。因此，当有（i）训练一个非常大的网络（训练过程会遵循上图中的绿色曲线）；(ii)拥有大规模数据 这两个条件满足时，你将得到最好的表现。还有一些其他的细节，例如神经网路的结构也很重要，并且在这个领域中有很多创新工作的提出。但目前来说，提高网络表现性能的相对可靠地方法就是(i)训练更大的网络(ii)收集更多数据。满足条件（i）和（ii）的过程是相当复杂的，本书将详细讨论如何完成这项工作的细节。首先，我们将从既能用于传统学习算法又能用于神经网络的通用策略开始，然后讲述构建深度学习系统的最现代的策略。[注释1]: 下图表示神经网络在小规模数据中表现挺好。但这种好的程度，不如神经网络在大规模数据中的表现好的程度（可以看出随着数据规模增大，Large NN倾斜越大）。在小规模数据中，传统算法表现的好与不好取决于如何手工设计特征。例如，如果你有20个训练样例，选择逻辑回归还是神经网络并不重要，手工设计特征将比选择算法对结果影响更大。但是如果有100万样例，还是选择神经网络把。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://mengmengmiao.github.io/tags/翻译/"}]},{"title":"MLY翻译 -- 3.Prerequisites and Notation","date":"2017-01-27T01:47:11.000Z","path":"2017/01/27/MLY-Prerequisites-and-Notation/","text":"如果你学习过机器学习课程，或者有使用监督学习的经验，你将能够更好理解这本书。本书中，我在讲述下面的章节时，会假设你对监督学习很熟悉。监督学习是在有标签的数据(x,y)中学习从x映射到y的一个函数，线性回归、逻辑回归、神经网络都是监督学习算法。目前存在很多机器学习的形式，但机器学习产生的实际价值多数都是监督学习带来的。在这本书中，我将会多次提到神经网络（即深度学习）。为学习这本书，你需要对神经网络（或深度学习）有一个基本的理解。如果你对神经网络（或深度学习）不理解，你可以看Coursera上的机器学习的前三个星期的课程，网址是http://ml-class.org","tags":[{"name":"翻译","slug":"翻译","permalink":"https://mengmengmiao.github.io/tags/翻译/"}]},{"title":"MLY翻译 -- 2.How to use this book to help your team?","date":"2017-01-25T13:47:08.000Z","path":"2017/01/25/Machine-Learning-Yearning-How-to-use-this-book-to-help-your-team/","text":"在读完这本书后，你将会对“如何为机器学习项目设定技术方向”有一个深入的理解。但是你的队友可能不理解你为什么偏向那个技术方向，例如你想让你队友们定义一个单数评价矩阵，但是他们对此不信服。你将会如何说服他们？这就是我将章节设置得如此短的原因：你可以将1-2页的内容打印出来，让你的队友读一读。对事务优先级的改变，将对你的团队的工作效率有很大的影响。多提几个对团队有帮助的改变策略，你就会成为众人眼中的超人啦！","tags":[{"name":"翻译","slug":"翻译","permalink":"https://mengmengmiao.github.io/tags/翻译/"}]},{"title":"MLY翻译 -- 1.Why Machine Learning Strategy?","date":"2017-01-25T13:42:47.000Z","path":"2017/01/25/Machine-Learning-Yearning-Why-Machine-Learning-Strategy/","text":"机器学习是很多应用的基础，如网页搜索，反垃圾邮件，语音识别，推荐系统等。如果你的团队正在做一个基于机器学习的应用，这本书能够帮你的团队取得快速的进步。 一个例子：提供猫图片的创业公司假如你现在正在创建一个为猫奴提供很多猫图片的公司，你用神经网络建立一个从图片中检测猫的计算机视觉系统。但悲剧的是，你发现你的学习算法精度不够，面临提高猫检测器精度的巨大压力，你要怎么做？你的小团队很给力，他们提出以下解决问题的方向： 收集更多数据：收集更多猫的图片 收集多样化训练数据：例如，收集具有不同姿势的猫图片；收集具有不同毛色的猫图片；收集拍摄时相机参数设置不同的图片 训练时间长一点儿：将梯度下降法的循环次数设置多一点儿 尝试更大的神经网络，所谓更大是指层数更多或者说隐藏单元更多或者说权重参数更多。 尝试更小的神经网络 尝试添加正则化项（例如L2正则） 改变神经网络的结构（例如改变激活函数，隐藏单元等） …… 在以上所述的方向中，如果能你能选择一个正确的方向，你将会建立一个领先于他人的猫图片平台，你的创业公司也会成功。若你选择一个不好的方向，你可能会浪费几个月。你将如何处理？这本书将会告诉你如何处理。对于多数机器学习问题，我们都能找到一些线索，这些线索能够告诉我们什么是有效的尝试，什么是无效的尝试。学会解读这些线索，将可能节约你数月甚至数年的开发时间。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://mengmengmiao.github.io/tags/翻译/"}]}]